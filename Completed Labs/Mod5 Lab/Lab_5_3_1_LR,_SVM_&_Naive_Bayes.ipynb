{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XebDJ3UnS3n3"
   },
   "source": [
    "<div>\n",
    "<img src=https://www.institutedata.com/wp-content/uploads/2019/10/iod_h_tp_primary_c.svg width=\"300\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e_-HjrL6S3n5"
   },
   "source": [
    "# Lab 5.3.1 \n",
    "# *Logistic Regression, Support Vector Machines & Naive Bayes*\n",
    "\n",
    "SVMs use linear algebra to find an (n-1)-dimensional boundary that separates classes within an n-dimensional space. In practical terms, this technique provides a conceptually simple way to predict class membership from a set of features. \n",
    "\n",
    "The standard (linear) SVM is immediately applicable to linear classification problems. Furthermore, by applying transformations to the feature space it is possible to tackle nonlinear classificaiton problems. These transforms are called *kernels*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "azVVNUxHYKej"
   },
   "source": [
    "### 1. Load Data\n",
    "\n",
    "Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image. n the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: \"Robust Linear Programming Discrimination of Two Linearly Inseparable Sets\", Optimization Methods and Software 1, 1992, 23-34].\n",
    "\n",
    "This database is also available through the UW CS ftp server: ftp ftp.cs.wisc.edu cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
    "\n",
    "Also can be found on UCI Machine Learning Repository: https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "1) ID number 2) Diagnosis (M = malignant, B = benign) 3-32)\n",
    "\n",
    "Ten real-valued features are computed for each cell nucleus:\n",
    "\n",
    "a) radius (mean of distances from center to points on the perimeter) b) texture (standard deviation of gray-scale values) c) perimeter d) area e) smoothness (local variation in radius lengths) f) compactness (perimeter^2 / area - 1.0) g) concavity (severity of concave portions of the contour) h) concave points (number of concave portions of the contour) i) symmetry j) fractal dimension (\"coastline approximation\" - 1)\n",
    "\n",
    "The mean, standard error and \"worst\" or largest (mean of the three largest values) of these features were computed for each image, resulting in 30 features. For instance, field 3 is Mean Radius, field 13 is Radius SE, field 23 is Worst Radius.\n",
    "\n",
    "All feature values are recoded with four significant digits.\n",
    "\n",
    "Missing attribute values: none\n",
    "\n",
    "Class distribution: 357 benign, 212 malignant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from matplotlib import cm\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython import display\n",
    "\n",
    "import tqdm\n",
    "from tqdm.notebook import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T05:13:16.458182Z",
     "start_time": "2019-05-09T05:13:16.454244Z"
    },
    "id": "aICmn_7xYKek"
   },
   "outputs": [],
   "source": [
    "breast_cancer_csv = 'dat/breast-cancer-wisconsin-data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer_data = pd.read_csv(breast_cancer_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FPRqG96QYKen"
   },
   "source": [
    "### 2. EDA \n",
    "\n",
    "- Explore dataset. Clean data (if required)\n",
    "\n",
    "\n",
    "- Define Target, Predictors\n",
    "- Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer_data.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the last columns which is unnamed\n",
    "breast_cancer_data.columns[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer_data.drop(columns=breast_cancer_data.columns[-1], \n",
    "        axis=1, \n",
    "        inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer_data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = breast_cancer_data.diagnosis\n",
    "y.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictors Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take all columns except target as predictor columns\n",
    "predictor_columns = [c for c in breast_cancer_data.columns if c != 'diagnosis' and c != 'id']\n",
    "# Load the dataset as a pandas data frame\n",
    "X = pd.DataFrame(breast_cancer_data, columns = predictor_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Omwx5vVbYKeo"
   },
   "source": [
    "### 3. Logistic Regression Model\n",
    "\n",
    "#### 3.1 Use Logistic Regression (liblinear solver)\n",
    "\n",
    "Use Logistic Regression and examine accuracy score, confusion matrix, classification report for that model.\n",
    "\n",
    "- Evaluate Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log res Accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model\n",
    "logres = LogisticRegression(max_iter=2000)\n",
    "\n",
    "# Fit Model\n",
    "logres.fit(X_train, y_train)\n",
    "print('Training set score: ', logres.score(X_train, y_train))\n",
    "print('Test set score: ', logres.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted labels (class):\n",
    "y_pred = logres.predict(X_test)\n",
    "print('y_pred: ', y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log res Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "confusion_matrix_df = pd.DataFrame(confusion_matrix, columns=['predicted_healthy','predicted_cancer']).rename(index={0: 'is_healthy', 1: 'is_cancer'})\n",
    "print(confusion_matrix_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log res Classification report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The traditional F-measure or balanced F-score (F1 score) is the balance between of precision and recall:"
   ]
  },
  {
   "attachments": {
    "f1_score.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![f1_score.png](attachment:f1_score.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report = metrics.classification_report(y_test, y_pred)\n",
    "\n",
    "print(classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mogg_w8vYKep"
   },
   "source": [
    "### 4. Support Vector Machine\n",
    "\n",
    "#### 4.1 Use Support Vector Machine (linear)\n",
    "\n",
    "Use Support Vector Machine and examine accuracy score, confusion matrix, classification report for that model.\n",
    "\n",
    "- Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#svc = svm.SVC(C=1000, kernel='linear', random_state=1)\n",
    "svc = make_pipeline(StandardScaler(), svm.SVC(C=1000, kernel='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model (linear kernal), without regularisation (make C large):\n",
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training set score: ', svc.score(X_train, y_train))\n",
    "print('Test set score: ', svc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted labels (class):\n",
    "y_pred = svc.predict(X_test)\n",
    "print('y_pred: ', y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "confusion_matrix_df = pd.DataFrame(confusion_matrix, columns=['predicted_healthy','predicted_cancer']).rename(index={0: 'is_healthy', 1: 'is_cancer'})\n",
    "print(confusion_matrix_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report = metrics.classification_report(y_test, y_pred)\n",
    "\n",
    "print(classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fdzQkTb7YKeq"
   },
   "source": [
    "### 5. Naive Bayes\n",
    "#### 5.1 Use Naive Bayes (Gaussian classifier)\n",
    "\n",
    "Use Naive Bayes and examine accuracy score, confusion matrix, classification report for that model.\n",
    "\n",
    "- Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GNB accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training set score: ', gnb.score(X_train, y_train))\n",
    "print('Test set score: ', gnb.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gnb.predict(X_test)\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\"\n",
    "       % (X_test.shape[0], (y_test != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GNB confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "confusion_matrix_df = pd.DataFrame(confusion_matrix, columns=['predicted_healthy','predicted_cancer']).rename(index={0: 'is_healthy', 1: 'is_cancer'})\n",
    "print(confusion_matrix_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GNB classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report = metrics.classification_report(y_test, y_pred)\n",
    "\n",
    "print(classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VoGxthaeYKer"
   },
   "source": [
    "### 6. Gridsearch optimal parameters for models.\n",
    "\n",
    "Is there any difference between accuracy score of Logistic Regression, SVM and Naive Bayes? Use grid search to find optimal parameters for Logistic Regression and SVM models.\n",
    "\n",
    "> Hyper-parameters are parameters that are not directly learnt within estimators. In scikit-learn they are passed as arguments to the constructor of the estimator classes. Typical examples include C, kernel and gamma for Support Vector Classifier, alpha for Lasso, etc.\n",
    "\n",
    "> It is possible and recommended to search the hyper-parameter space for the best cross validation score.\n",
    "\n",
    "> https://scikit-learn.org/stable/modules/grid_search.html#grid-search\n",
    "\n",
    "**Note:** It'll take time to execute this. After running the cell, wait for result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UeqrbsyNYKes"
   },
   "source": [
    "#### 6.1 Find Best Estimator For Logistic Regression \n",
    "\n",
    "Find out how these parameters effect model. Find out the best estimator, score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T05:40:29.397881Z",
     "start_time": "2019-05-09T05:40:29.392602Z"
    },
    "id": "UkQ9RBQZYKet"
   },
   "outputs": [],
   "source": [
    "lr_params = {\n",
    "    'penalty': ['l1','l2'],\n",
    "    'C': [1, 10, 100],\n",
    "    'solver': ['saga'],\n",
    "    'max_iter': [5000]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logres = LogisticRegression()\n",
    "lr_clf = GridSearchCV(logres, lr_params, return_train_score=True, n_jobs=-1, verbose=9)\n",
    "lr_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lr_clf.best_params_)\n",
    "print(lr_clf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T05:23:14.036840Z",
     "start_time": "2019-05-09T05:23:14.032847Z"
    },
    "id": "ioLgY3bxYKev"
   },
   "source": [
    "#### 6.2 Find Best Estimator For SVM\n",
    "\n",
    "Find out how these parameters effect model. Find out the best estimator, score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T05:40:31.617090Z",
     "start_time": "2019-05-09T05:40:31.612996Z"
    },
    "id": "vgi61VpWYKew"
   },
   "outputs": [],
   "source": [
    "svc_params = {\n",
    "    'C': [1, 10, 100, 1000],\n",
    "    'gamma': ['scale' , 'auto', 0.001, 0.0001],\n",
    "    'kernel': ['linear','rbf'],\n",
    "    'probability': [True]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = svm.SVC()\n",
    "svc_clf = GridSearchCV(svc, svc_params, return_train_score=True, n_jobs=-1, verbose=9)\n",
    "svc_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(svc_clf.best_params_)\n",
    "print(svc_clf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T05:23:59.157703Z",
     "start_time": "2019-05-09T05:23:59.153713Z"
    },
    "id": "HrS04DfuYKez"
   },
   "source": [
    "#### 6.3 Plot the ROC curve for the SVM, Logistic Regressions and Naive Bayes on the same plot\n",
    "\n",
    "Find out which model performs better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_pp_lr = lr_clf.predict_proba(X_test)\n",
    "yhat_pp_svm = svc_clf.predict_proba(X_test)\n",
    "yhat_pp_gnb = gnb.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(yhat_pp_lr))\n",
    "print(np.shape(yhat_pp_svm))\n",
    "print(np.shape(yhat_pp_gnb))\n",
    "print(np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T05:28:56.671590Z",
     "start_time": "2019-05-09T05:28:56.421258Z"
    },
    "id": "q9TBM2axYKe0",
    "outputId": "8f525757-6f7f-4a8b-d154-235ae82cfdf6"
   },
   "outputs": [],
   "source": [
    "# For class 1, find the area under the curve\n",
    "# Find fpr, tpr\n",
    "fpr_lr, tpr_lr, _ = metrics.roc_curve(y_test, lr_pp_df.iloc[:,1], pos_label='M')\n",
    "fpr_svm, tpr_svm, _ = metrics.roc_curve(y_test, svm_pp_df.iloc[:,1], pos_label='M')\n",
    "fpr_gnb, tpr_gnb, _ = metrics.roc_curve(y_test, gnb_pp_df.iloc[:,1], pos_label='M')\n",
    "\n",
    "# Find auc\n",
    "roc_auc_lr = metrics.auc(fpr_lr, tpr_lr)\n",
    "roc_auc_svm = metrics.auc(fpr_svm, tpr_svm)\n",
    "roc_auc_gnb = metrics.auc(fpr_gnb, tpr_gnb)\n",
    "\n",
    "# Plot of a ROC curve for class 1 (has_cancer)\n",
    "plt.figure(figsize=[8,8])\n",
    "\n",
    "# Plot fpr, tpr\n",
    "lw = 2\n",
    "plt.plot(fpr_lr, tpr_lr, color='darkorange', lw = lw, label = 'ROC curve for log res (area = %0.2f)' % roc_auc_lr)\n",
    "plt.plot(fpr_svm, tpr_svm, color='red', lw = lw, label = 'ROC curve for SVM (area = %0.2f)' % roc_auc_svm)\n",
    "plt.plot(fpr_gnb, tpr_gnb, color='blue', lw = lw, label = 'ROC curve for Naive Bayes (area = %0.2f)' % roc_auc_gnb)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=4)\n",
    "\n",
    "plt.xlim([-0.05, 1.0])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=18)\n",
    "plt.ylabel('True Positive Rate', fontsize=18)\n",
    "plt.title('Receiver Operating Characteristic: M', fontsize=18)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WrSrz3AAYKe3"
   },
   "source": [
    "### 7. [BONUS] Learning Curve\n",
    "\n",
    "A learning curve shows the validation and training score of an estimator for varying numbers of training samples. It is a tool to find out how much we benefit from adding more training data and whether the estimator suffers more from a variance error or a bias error. If both the validation score and the training score converge to a value that is too low with increasing size of the training set, we will not benefit much from more training data.\n",
    "\n",
    "Plot \"learning curves\" for the best models of each. This is a great way see how training/testing size affects the scores. Look at the documentation for how to use this function in sklearn.\n",
    "\n",
    "http://scikit-learn.org/stable/modules/learning_curve.html#learning-curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T05:22:19.657638Z",
     "start_time": "2019-05-09T05:22:19.653657Z"
    },
    "id": "3Zleg5E-YKe4"
   },
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html#sphx-glr-auto-examples-model-selection-plot-learning-curve-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "X, y = load_digits(return_X_y=True)\n",
    "\n",
    "param_range = np.logspace(-6, -1, 5)\n",
    "train_scores, test_scores = validation_curve(\n",
    "    SVC(), X, y, param_name=\"gamma\", param_range=param_range,\n",
    "    scoring=\"accuracy\", n_jobs=1)\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.title(\"Validation Curve with SVM\")\n",
    "plt.xlabel(r\"$\\gamma$\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0.0, 1.1)\n",
    "lw = 2\n",
    "plt.semilogx(param_range, train_scores_mean, label=\"Training score\",\n",
    "             color=\"darkorange\", lw=lw)\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                 color=\"darkorange\", lw=lw)\n",
    "plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "             color=\"navy\", lw=lw)\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                 color=\"navy\", lw=lw)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tE8SgkpSYKe7"
   },
   "source": [
    "**References**\n",
    "\n",
    "[Breast Cancer Wisconsin (Diagnostic) Data Set](https://www.kaggle.com/uciml/breast-cancer-wisconsin-data/downloads/breast-cancer-wisconsin-data.zip/2)\n",
    "\n",
    "[Validation curves: plotting scores to evaluate models](https://scikit-learn.org/stable/modules/learning_curve.html#learning-curves)\n",
    "\n",
    "[In-Depth: Support Vector Machines](https://jakevdp.github.io/PythonDataScienceHandbook/05.07-support-vector-machines.html)\n",
    "\n",
    "[Understanding Support Vector Machine algorithm from examples (along with code)](https://www.analyticsvidhya.com/blog/2017/09/understaing-support-vector-machine-example-code/)\n",
    "\n",
    "[Tuning the hyper-parameters of an estimator](https://scikit-learn.org/stable/modules/grid_search.html#grid-search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RERADKgNFq9T"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "> > > > > > > > > © 2021 Institute of Data\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lab 5.3.1 LR, SVM & Naive Bayes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
